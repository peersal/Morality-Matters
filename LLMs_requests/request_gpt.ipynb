{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0bdf04-8d95-449d-9243-839018c33dba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### In this notebook we get the request from gpt 3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7315cce5-2385-442a-bd74-3a706a122897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df790a-2ce4-4778-9ac3-56cdb9279e6a",
   "metadata": {},
   "source": [
    "#### TODO: Get projekt key apply to final prompt df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe563fd8-4cda-42e1-8ffa-41366e6b34a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switch</td>\n",
       "      <td>Consider following szenario where you are the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loop</td>\n",
       "      <td>Consider following szenario where you are the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Footbridge</td>\n",
       "      <td>Consider following szenario where you are the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Switch_apples</td>\n",
       "      <td>Consider following szenario where you are the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Loop_apples</td>\n",
       "      <td>Consider following szenario where you are the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Scenario                                             Prompt\n",
       "0         Switch  Consider following szenario where you are the ...\n",
       "1           Loop  Consider following szenario where you are the ...\n",
       "2     Footbridge  Consider following szenario where you are the ...\n",
       "3  Switch_apples  Consider following szenario where you are the ...\n",
       "4    Loop_apples  Consider following szenario where you are the ..."
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/prompts.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f6f48-97d1-4b16-a0ea-46f3fe9b5b3a",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2c21ec6-26e7-4503-9aa4-0507074dbde5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = \"TNfeRW6EtrEGu4T536a4\"\n",
    "openai.api_key = api_key\n",
    "openai.api_base= \"http://91.107.239.71:80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c047539-c58a-45c7-99c0-4976246b0ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B - I would choose not to redirect the trolley to the different track and let it proceed, resulting in the death of five workers. This decision is based on the principle of minimizing direct harm, as by not actively choosing to redirect the trolley, I am not directly responsible for the death of one person, whereas actively redirecting the trolley would make me morally complicit in their death.\n"
     ]
    }
   ],
   "source": [
    "# Send a request to the API\n",
    "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                                    messages=[{\"role\": \"user\", \"content\": df.iloc[0][\"Prompt\"]}],\n",
    "                                    max_tokens=200,\n",
    "                                    n=1)\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55cdcf84-23ba-47d2-9cf1-106367e3b222",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B - I would choose not to redirect the trolley to the different track and let it proceed, resulting in the death of five workers. This decision is based on the principle of minimizing direct harm, as by not actively choosing to redirect the trolley, I am not directly responsible for the death of one person, whereas actively redirecting the trolley would make me morally complicit in their death.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b5e1bdf-ace9-4505-a979-5e2fa4db3fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gpt_responses(n):\n",
    "    responses = {}\n",
    "    for i  in range(n):\n",
    "        responses[i + 1] = []\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Rows\"):\n",
    "        response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
    "                            messages=[{\"role\": \"user\", \"content\":row[\"Prompt\"]}],\n",
    "                            max_tokens=200,\n",
    "                            n=n)\n",
    "        \n",
    "        j = 1\n",
    "        for i in response[\"choices\"]:\n",
    "            responses[j].append(i[\"message\"][\"content\"])\n",
    "            j += 1\n",
    "    \n",
    "    return responses\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81ae844c-4a51-4aac-abdf-771e765cea37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 18/18 [00:44<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "responses = get_gpt_responses(5)\n",
    "for key, value in responses.items():\n",
    "    df[f\"response_{key}\"] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f78aa980-6116-43d3-9adb-458eaead26d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/results_gpt.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656bfcd9-b359-429b-aa08-ac7346e67186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
